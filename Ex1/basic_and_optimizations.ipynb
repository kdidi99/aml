{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1. / (1 + np.exp(-z))\n",
    "\n",
    "lam = 1\n",
    "def gradient(beta, X, y):\n",
    "    N = y.shape[0]\n",
    "    temp = (1 - sigmoid(y * np.dot(X, beta))) * (-y)\n",
    "    return np.dot(X.T, temp) / N + beta / lam\n",
    "\n",
    "def predict(beta, X):\n",
    "    y = np.dot(X, beta)\n",
    "    y[y > 0] = 1\n",
    "    y[y < 0] = -1\n",
    "    return y\n",
    "\n",
    "def zero_one_loss(y_prediction, y_truth):\n",
    "    return sum(y_prediction != y_truth) / len(y_prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, beta_0, tau_0, gamma, m, train = False):\n",
    "    beta_new = beta_0 - tau_0 * gradient(beta_0, X, y)\n",
    "    for t in range(1, m):\n",
    "        tau = tau_0 / (1 + gamma * t)\n",
    "        beta_new = beta_new - tau * gradient(beta_new, X, y)\n",
    "        \n",
    "        if train:\n",
    "            print(zero_one_loss(predict(beta_new, X), y))\n",
    "    return beta_new\n",
    "\n",
    "\n",
    "def stochastic_gradnient(X, y, beta_0, tau_0, gamma, m):\n",
    "    N = X.shape[0]\n",
    "    i = random.sample(range(N - 1), 1)\n",
    "    beta_new = beta_0 - tau_0 * gradient(beta_0, X[i], y[i])\n",
    "    for t in range(1, m):\n",
    "        i = random.sample(range(N - 1), 1)\n",
    "        tau = tau_0 / (1 + gamma * t)\n",
    "        beta_new = beta_new - tau * gradient(beta_new, X[i], y[i])\n",
    "        \n",
    "        print(zero_one_loss(predict(beta_new, X), y))\n",
    "    return beta_new\n",
    "    \n",
    "    \n",
    "def minibatch_gradnient(X, y, beta_0, tau_0, gamma, m, B):\n",
    "    N = X.shape[0]\n",
    "    i = random.sample(range(N - 1), B)\n",
    "    beta_new = beta_0 - tau_0 * gradient(beta_0, X[i], y[i])\n",
    "    for t in range(m):\n",
    "        i = random.sample(range(N - 1), B)\n",
    "        tau = tau_0 / (1 + gamma * t)\n",
    "        beta_new = beta_new - tau * gradient(beta_new, X[i], y[i])\n",
    "        \n",
    "        print(zero_one_loss(predict(beta_new, X), y))\n",
    "    return beta_new\n",
    "\n",
    "\n",
    "def momentum_gradnient(X, y, beta_0, g_0, tau_0, gamma, m, mi):\n",
    "    N = X.shape[0]\n",
    "    i = random.sample(range(N - 1), 1)\n",
    "    g_new = mi * g_0 + (1 - mi) * gradient(beta_0, X[i], y[i])\n",
    "    beta_new = beta_0 - tau_0 * g_new\n",
    "    for t in range(m):\n",
    "        i = random.sample(range(N - 1), 1)\n",
    "        tau = tau_0 / (1 + gamma * t)\n",
    "        g_new = mi * g_new + (1 - mi) * gradient(beta_new, X[i], y[i])\n",
    "        beta_new = beta_new - tau * g_new\n",
    "        \n",
    "        print(zero_one_loss(predict(beta_new, X), y))\n",
    "    return beta_new  \n",
    "\n",
    "\n",
    "def adam(X, y, beta_0, g_0, q_0, m, mi_1 = 0.9, mi_2 = 0.999, e = 1e-8, tau = 0.0001):\n",
    "    N = X.shape[0]\n",
    "    i = random.sample(range(N - 1), 1)\n",
    "    g_new = mi_1 * g_0 + (1 - mi_1) * gradient(beta_0, X[i], y[i])\n",
    "    q_new = mi_2 * q_0 + (1 - mi_2) * (gradient(beta_0, X[i], y[i])) ** 2\n",
    "    \n",
    "    g_prim = g_new / (1 - mi_1)\n",
    "    q_prim = q_new / (1 - mi_2)\n",
    "    \n",
    "    beta_new = beta_0 - g_prim * tau / (np.sqrt(q_prim) + e)\n",
    "    \n",
    "    for t in range(m):\n",
    "        i = random.sample(range(N - 1), 1)\n",
    "        \n",
    "        g_new = mi_1 * g_new + (1 - mi_1) * gradient(beta_new, X[i], y[i])\n",
    "        q_new = mi_2 * q_new + (1 - mi_2) * (gradient(beta_new, X[i], y[i])) ** 2\n",
    "        \n",
    "        g_prim = g_new / (1 - mi_1)\n",
    "        q_prim = q_new / (1 - mi_2)\n",
    "    \n",
    "        beta_new = beta_new - g_prim * tau / (np.sqrt(q_prim) + e)\n",
    "        \n",
    "        print(zero_one_loss(predict(beta_new, X), y))\n",
    "    return beta_new \n",
    "\n",
    "\n",
    "def stochastic_average_gradient(X, y, beta, tau, gamma, mi = None, m = 10, eps = 0.000001):\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    g_stored = - y * sigmoid(- y * (np.dot(X, beta))) * X\n",
    "    g = np.sum(g_stored, axis = 0).reshape(D, 1) / N\n",
    "    for t in range(m):\n",
    "        i = random.sample(range(N - 1), 1)\n",
    "        tau = tau / (1 + gamma * t)\n",
    "        g_temp = - y[i] * X[i] * sigmoid(- y[i] * np.dot(X[i], beta))\n",
    "        g = g + (g_temp - g_stored[i]).T / N\n",
    "        g_stored[i] = g_temp \n",
    "        beta = beta * (1 - tau /lam) - tau * g\n",
    "\n",
    "    return beta\n",
    "\n",
    "\n",
    "def dual_coordinate_ascent(X, y, beta_0 = None, tau = None, gamma = None, mi = None, m = 10, eps = 0.000001):\n",
    "    N = X.shape[0]\n",
    "    alpha = np.random.rand(N)\n",
    "    alpha = alpha.reshape(-1,1)\n",
    "    temp = y * alpha\n",
    "    beta = np.dot(feature_matrix.T, temp) * lam / N\n",
    "    for t in range(m):\n",
    "        i = random.sample(range(N - 1), 1)\n",
    "        print(alpha[i])\n",
    "        f_prim = y[i] * np.dot(X[i], beta) + np.log(alpha[i]/(1 - alpha[i]))\n",
    "        f_bis = np.dot(X[i], X[i].T) * lam / N + 1 / (alpha[i] * (1 - alpha[i]))\n",
    "        \n",
    "        alpha_old = alpha[i]\n",
    "        alpha[i] = np.clip(alpha[i] - f_prim / f_bis, eps, 1 - eps)\n",
    "        \n",
    "        beta = beta + lam * y[i] * X[i].T * (alpha[i] - alpha_old)\n",
    "        \n",
    "    return beta \n",
    "\n",
    "\n",
    "def newton_raphson(X, y, beta, tau = None, gamma = None, mi = None, m = 10):\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    for t in range(m):\n",
    "        scores = np.dot(X, beta)\n",
    "        labels = y / sigmoid(y * scores)\n",
    "        temp = (sigmoid(scores) * sigmoid(- scores)).reshape(-1)\n",
    "        W = np.diag(temp) * lam / N  \n",
    "        beta = np.linalg.inv(np.identity(D) + X.T @ W @ X) @ X.T @ W @ (scores + labels)\n",
    "    return beta "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
